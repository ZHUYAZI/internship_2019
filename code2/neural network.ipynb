{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ot</th>\n",
       "      <th>Dt</th>\n",
       "      <th>DUREE</th>\n",
       "      <th>NBTRAJTC</th>\n",
       "      <th>dist</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18300.0</td>\n",
       "      <td>19800.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20362.956563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34200.0</td>\n",
       "      <td>35340.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1941.648784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>37800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23648.467181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27000.0</td>\n",
       "      <td>31800.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35474.638828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27000.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35713.582850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13400.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27900.0</td>\n",
       "      <td>33600.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32614.260685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48600.0</td>\n",
       "      <td>51300.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16319.620094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19800.0</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19009.471324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>30300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66000.0</td>\n",
       "      <td>66600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1421.267040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21600.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41824.872982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25200.0</td>\n",
       "      <td>32400.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24935.917870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27000.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30084.215130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24300.0</td>\n",
       "      <td>29100.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20260.799589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25200.0</td>\n",
       "      <td>27060.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13061.393494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25200.0</td>\n",
       "      <td>29040.0</td>\n",
       "      <td>3840.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28540.847920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26100.0</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39805.778475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47700.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6484.597135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26100.0</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35467.449866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>26700.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30620.581314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27000.0</td>\n",
       "      <td>33300.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28338.136848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25800.0</td>\n",
       "      <td>31500.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41388.162559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22800.0</td>\n",
       "      <td>29400.0</td>\n",
       "      <td>6600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62309.068361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29400.0</td>\n",
       "      <td>35700.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41629.316593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26100.0</td>\n",
       "      <td>30600.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45632.554169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18600.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54800.091241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>24300.0</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65060.971404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22800.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24087.548651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24300.0</td>\n",
       "      <td>29400.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46044.000695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21489</th>\n",
       "      <td>57600.0</td>\n",
       "      <td>64800.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45449.312426</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21490</th>\n",
       "      <td>62100.0</td>\n",
       "      <td>63900.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16530.275255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21491</th>\n",
       "      <td>60300.0</td>\n",
       "      <td>62100.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5122.499390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21492</th>\n",
       "      <td>71100.0</td>\n",
       "      <td>71700.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6365.532185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21493</th>\n",
       "      <td>70200.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6484.597135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21494</th>\n",
       "      <td>62400.0</td>\n",
       "      <td>62700.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2418.677324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21495</th>\n",
       "      <td>72000.0</td>\n",
       "      <td>72120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>806.225775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21496</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>46800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7317.103252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>63900.0</td>\n",
       "      <td>65400.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8905.054744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21498</th>\n",
       "      <td>66600.0</td>\n",
       "      <td>68700.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>412.310563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21499</th>\n",
       "      <td>61200.0</td>\n",
       "      <td>65400.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31196.474160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21500</th>\n",
       "      <td>58500.0</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4045.985665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>69300.0</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5385.164807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21502</th>\n",
       "      <td>60900.0</td>\n",
       "      <td>61200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>412.310563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>72900.0</td>\n",
       "      <td>73500.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2400.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21504</th>\n",
       "      <td>47700.0</td>\n",
       "      <td>49800.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5685.068161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21505</th>\n",
       "      <td>71100.0</td>\n",
       "      <td>72900.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18917.980865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21506</th>\n",
       "      <td>54000.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47071.222631</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21507</th>\n",
       "      <td>73800.0</td>\n",
       "      <td>74700.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21508</th>\n",
       "      <td>64800.0</td>\n",
       "      <td>65700.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>447.213595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21509</th>\n",
       "      <td>63000.0</td>\n",
       "      <td>65100.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4024.922359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21510</th>\n",
       "      <td>73800.0</td>\n",
       "      <td>75600.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10748.023074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21511</th>\n",
       "      <td>67800.0</td>\n",
       "      <td>72600.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29138.634148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21512</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>90300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>64500.0</td>\n",
       "      <td>67800.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16737.084573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21514</th>\n",
       "      <td>61800.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2195.449840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21515</th>\n",
       "      <td>62400.0</td>\n",
       "      <td>68280.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48206.327386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516</th>\n",
       "      <td>63900.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36748.469356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21517</th>\n",
       "      <td>79500.0</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36531.219525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>84600.0</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5825.804665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21519 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ot       Dt   DUREE  NBTRAJTC          dist  parking\n",
       "0      18300.0  19800.0  1500.0       1.0  20362.956563        1\n",
       "1      34200.0  35340.0  1140.0       1.0   1941.648784        1\n",
       "2      36000.0  37800.0  1800.0       2.0  23648.467181        1\n",
       "3      27000.0  31800.0  4800.0       3.0  35474.638828        1\n",
       "4      27000.0  32400.0  5400.0       3.0  35713.582850        1\n",
       "...        ...      ...     ...       ...           ...      ...\n",
       "21514  61800.0  63000.0  1200.0       1.0   2195.449840        0\n",
       "21515  62400.0  68280.0  5880.0       2.0  48206.327386        0\n",
       "21516  63900.0  69000.0  5100.0       2.0  36748.469356        0\n",
       "21517  79500.0  82500.0  3000.0       2.0  36531.219525        0\n",
       "21518  84600.0  86400.0  1800.0       1.0   5825.804665        0\n",
       "\n",
       "[21519 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1_true=pd.read_csv('/home/yazi/Documents/stage/data/data1_true.csv',delimiter=';',encoding='iso 8859-1')\n",
    "data2_true=pd.read_csv('/home/yazi/Documents/stage/data/data2_true.csv',delimiter=';',encoding='iso 8859-1')\n",
    "data1_false=pd.read_csv('/home/yazi/Documents/stage/data/data1_false.csv',delimiter=';',encoding='iso 8859-1')\n",
    "data2_false=pd.read_csv('/home/yazi/Documents/stage/data/data2_false.csv',delimiter=';',encoding='iso 8859-1')\n",
    "Data_Train=pd.concat([data1_true,data2_true,data1_false,data2_false],ignore_index=True)\n",
    "Data_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data_Train.drop('parking', axis=1)\n",
    "y = Data_Train['parking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5958114 , -1.66829122, -0.57514726, -0.89708632,  0.93431633],\n",
       "       [-0.77721666, -0.86264201, -0.75408122, -0.89708632, -0.61836558],\n",
       "       [-0.68454556, -0.73510681, -0.42603562,  0.23129809,  1.21124307],\n",
       "       ...,\n",
       "       [ 0.75185653,  0.88241283,  1.21419238,  0.23129809,  2.31540661],\n",
       "       [ 1.55500608,  1.58230113,  0.17041092,  0.23129809,  2.29709521],\n",
       "       [ 1.81757421,  1.78449109, -0.42603562, -0.89708632, -0.29098065]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(y.astype(float))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.reshape([1,len(y_test)])\n",
    "y_train=y_train.reshape([1,len(y_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.transpose(X_train)\n",
    "X_test=np.transpose(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is  (5, 17215)\n",
      "y_train shape is  (1, 17215)\n",
      "X_test shape is  (5, 4304)\n",
      "y_test shape is  (1, 4304)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape is ',X_train.shape)\n",
    "print('y_train shape is ',y_train.shape)\n",
    "print('X_test shape is ',X_test.shape)\n",
    "print('y_test shape is ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    #n_x=5,n_y=1\n",
    "    X=tf.placeholder(tf.float32,[n_x,None],name=\"X\")\n",
    "    Y=tf.placeholder(tf.float32,[n_y,None],name=\"Y\")\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=create_placeholders(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'X:0' shape=(5, ?) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Y:0' shape=(1, ?) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    W1=tf.get_variable('W1',[4,5],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b1=tf.get_variable('b1',[4,1],initializer=tf.zeros_initializer())\n",
    "    W2=tf.get_variable('W2',[1,4],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b2=tf.get_variable('b2',[1,1],initializer=tf.zeros_initializer())\n",
    "    \n",
    "    parameters={'W1':W1,\n",
    "                'b1':b1,\n",
    "                'W2':W2,\n",
    "                'b2':b2\n",
    "               }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 19:07:53.196706 140673148917568 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(4, 5) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(4, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(1, 4) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(1, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    \"\"\"\n",
    "    LINEAR -> RELU -> LINEAR -> Sigmoid\n",
    "\n",
    "    in：\n",
    "        X - data[6,none]\n",
    "        parameters - :W,b\n",
    "\n",
    "    return：\n",
    "        Z2 - last linear\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)        # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)     # Z2 = np.dot(W2, a1) + b2\n",
    "\n",
    "\n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z2 = Tensor(\"Add_1:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X,Y = create_placeholders(5,1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z2 = forward_propagation(X,parameters)\n",
    "    print(\"Z2 = \" + str(Z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z2,Y):\n",
    "    logits = tf.transpose(Z2) \n",
    "    labels = tf.transpose(Y)  \n",
    "    cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y,logits=Z2))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 19:07:55.433845 140673148917568 deprecation.py:323] From /home/yazi/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X,Y = create_placeholders(5,1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z2 = forward_propagation(X,parameters)\n",
    "    cost = compute_cost(Z2,Y)\n",
    "    print(\"cost = \" + str(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,\n",
    "        learning_rate=0.0001,num_epochs=10000,print_cost=True,is_plot=True):\n",
    "    \"\"\"\n",
    "    实现一个三层的TensorFlow神经网络：LINEAR->RELU->LINEAR->Sigmoid\n",
    "\n",
    "    参数：\n",
    "        X_train - 训练集，维度为（输入大小（输入节点数量） = 12288, 样本数量 = 1080）\n",
    "        Y_train - 训练集分类数量，维度为（输出大小(输出节点数量) = 6, 样本数量 = 1080）\n",
    "        X_test - 测试集，维度为（输入大小（输入节点数量） = 12288, 样本数量 = 120）\n",
    "        Y_test - 测试集分类数量，维度为（输出大小(输出节点数量) = 6, 样本数量 = 120）\n",
    "        learning_rate - 学习速率\n",
    "        num_epochs - 整个训练集的遍历次数\n",
    "        mini_batch_size - 每个小批量数据集的大小\n",
    "        print_cost - 是否打印成本，每100代打印一次\n",
    "        is_plot - 是否绘制曲线图\n",
    "\n",
    "    返回：\n",
    "        parameters - 学习后的参数\n",
    "\n",
    "    \"\"\"\n",
    "    ops.reset_default_graph()                #能够重新运行模型而不覆盖tf变量\n",
    "    (n_x , m)  = X_train.shape               #获取输入节点数量和样本数\n",
    "    n_y = Y_train.shape[0]                   #获取输出节点数量\n",
    "    costs = []                               #成本集\n",
    "\n",
    "    #给X和Y创建placeholder\n",
    "    X,Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "    #初始化参数\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    #前向传播\n",
    "    Z2 = forward_propagation(X,parameters)\n",
    "\n",
    "    #计算成本\n",
    "    cost = compute_cost(Z2,Y)\n",
    "\n",
    "    #反向传播，使用Adam优化\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    #初始化所有的变量\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #开始会话并计算\n",
    "    with tf.Session() as sess:\n",
    "        #初始化\n",
    "        sess.run(init)\n",
    "\n",
    "        #正常训练的循环\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0  #每代的成本\n",
    "\n",
    "            #数据已经准备好了，开始运行session\n",
    "            _ , minibatch_cost = sess.run([optimizer,cost],feed_dict={X:X_train,Y:Y_train})\n",
    "\n",
    "            #计算这个minibatch在这一代中所占的误差\n",
    "            epoch_cost =  minibatch_cost\n",
    "\n",
    "            #记录并打印成本\n",
    "            ## 记录成本\n",
    "            if epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                #是否打印：\n",
    "                if print_cost and epoch % 100 == 0:\n",
    "                        print(\"epoch = \" + str(epoch) + \"    epoch_cost = \" + str(epoch_cost))\n",
    "\n",
    "        #是否绘制图谱\n",
    "        if is_plot:\n",
    "            plt.plot(np.squeeze(costs))\n",
    "            plt.ylabel('cost')\n",
    "            plt.xlabel('iterations (per tens)')\n",
    "            plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "            plt.show()\n",
    "\n",
    "        #保存学习后的参数\n",
    "        parameters = sess.run(parameters)\n",
    "        print(\"参数已经保存到session。\")\n",
    "\n",
    "        #计算当前的预测结果\n",
    "        correct_prediction = tf.equal(tf.argmax(Z2),tf.argmax(Y))\n",
    "\n",
    "        #计算准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "        print(\"训练集的准确率：\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print(\"测试集的准确率:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0    epoch_cost = 0.62939435\n",
      "epoch = 100    epoch_cost = 0.608187\n",
      "epoch = 200    epoch_cost = 0.58791685\n",
      "epoch = 300    epoch_cost = 0.5683561\n",
      "epoch = 400    epoch_cost = 0.5493379\n",
      "epoch = 500    epoch_cost = 0.5308853\n",
      "epoch = 600    epoch_cost = 0.5130251\n",
      "epoch = 700    epoch_cost = 0.4957638\n",
      "epoch = 800    epoch_cost = 0.47910002\n",
      "epoch = 900    epoch_cost = 0.46309984\n",
      "epoch = 1000    epoch_cost = 0.44776368\n",
      "epoch = 1100    epoch_cost = 0.43310544\n",
      "epoch = 1200    epoch_cost = 0.41912496\n",
      "epoch = 1300    epoch_cost = 0.40581048\n",
      "epoch = 1400    epoch_cost = 0.39315996\n",
      "epoch = 1500    epoch_cost = 0.38115743\n",
      "epoch = 1600    epoch_cost = 0.36979884\n",
      "epoch = 1700    epoch_cost = 0.35906345\n",
      "epoch = 1800    epoch_cost = 0.3489206\n",
      "epoch = 1900    epoch_cost = 0.3393383\n",
      "epoch = 2000    epoch_cost = 0.33028036\n",
      "epoch = 2100    epoch_cost = 0.3217178\n",
      "epoch = 2200    epoch_cost = 0.3136173\n",
      "epoch = 2300    epoch_cost = 0.30595472\n",
      "epoch = 2400    epoch_cost = 0.29869887\n",
      "epoch = 2500    epoch_cost = 0.2918334\n",
      "epoch = 2600    epoch_cost = 0.28532735\n",
      "epoch = 2700    epoch_cost = 0.27916518\n",
      "epoch = 2800    epoch_cost = 0.27332887\n",
      "epoch = 2900    epoch_cost = 0.26779968\n",
      "epoch = 3000    epoch_cost = 0.26256463\n",
      "epoch = 3100    epoch_cost = 0.25760338\n",
      "epoch = 3200    epoch_cost = 0.2528875\n",
      "epoch = 3300    epoch_cost = 0.24840735\n",
      "epoch = 3400    epoch_cost = 0.24416104\n",
      "epoch = 3500    epoch_cost = 0.2401416\n",
      "epoch = 3600    epoch_cost = 0.2363338\n",
      "epoch = 3700    epoch_cost = 0.23273908\n",
      "epoch = 3800    epoch_cost = 0.22934642\n",
      "epoch = 3900    epoch_cost = 0.22614235\n",
      "epoch = 4000    epoch_cost = 0.22313161\n",
      "epoch = 4100    epoch_cost = 0.22029872\n",
      "epoch = 4200    epoch_cost = 0.21763897\n",
      "epoch = 4300    epoch_cost = 0.21515648\n",
      "epoch = 4400    epoch_cost = 0.21284083\n",
      "epoch = 4500    epoch_cost = 0.21067783\n",
      "epoch = 4600    epoch_cost = 0.20866983\n",
      "epoch = 4700    epoch_cost = 0.20680721\n",
      "epoch = 4800    epoch_cost = 0.20507699\n",
      "epoch = 4900    epoch_cost = 0.20348094\n",
      "epoch = 5000    epoch_cost = 0.2020023\n",
      "epoch = 5100    epoch_cost = 0.2006265\n",
      "epoch = 5200    epoch_cost = 0.19935177\n",
      "epoch = 5300    epoch_cost = 0.19817676\n",
      "epoch = 5400    epoch_cost = 0.19708738\n",
      "epoch = 5500    epoch_cost = 0.19607939\n",
      "epoch = 5600    epoch_cost = 0.19514616\n",
      "epoch = 5700    epoch_cost = 0.19428582\n",
      "epoch = 5800    epoch_cost = 0.19349773\n",
      "epoch = 5900    epoch_cost = 0.19277008\n",
      "epoch = 6000    epoch_cost = 0.19209261\n",
      "epoch = 6100    epoch_cost = 0.19145928\n",
      "epoch = 6200    epoch_cost = 0.19087304\n",
      "epoch = 6300    epoch_cost = 0.19032967\n",
      "epoch = 6400    epoch_cost = 0.18982199\n",
      "epoch = 6500    epoch_cost = 0.18934199\n",
      "epoch = 6600    epoch_cost = 0.18888861\n",
      "epoch = 6700    epoch_cost = 0.18845974\n",
      "epoch = 6800    epoch_cost = 0.18804987\n",
      "epoch = 6900    epoch_cost = 0.18765482\n",
      "epoch = 7000    epoch_cost = 0.18726814\n",
      "epoch = 7100    epoch_cost = 0.18689053\n",
      "epoch = 7200    epoch_cost = 0.186513\n",
      "epoch = 7300    epoch_cost = 0.18613923\n",
      "epoch = 7400    epoch_cost = 0.18577409\n",
      "epoch = 7500    epoch_cost = 0.18541884\n",
      "epoch = 7600    epoch_cost = 0.18507355\n",
      "epoch = 7700    epoch_cost = 0.18472712\n",
      "epoch = 7800    epoch_cost = 0.18437962\n",
      "epoch = 7900    epoch_cost = 0.18403058\n",
      "epoch = 8000    epoch_cost = 0.1836734\n",
      "epoch = 8100    epoch_cost = 0.18331315\n",
      "epoch = 8200    epoch_cost = 0.18296492\n",
      "epoch = 8300    epoch_cost = 0.18261868\n",
      "epoch = 8400    epoch_cost = 0.18227932\n",
      "epoch = 8500    epoch_cost = 0.18195467\n",
      "epoch = 8600    epoch_cost = 0.18163836\n",
      "epoch = 8700    epoch_cost = 0.18132938\n",
      "epoch = 8800    epoch_cost = 0.18102083\n",
      "epoch = 8900    epoch_cost = 0.18071376\n",
      "epoch = 9000    epoch_cost = 0.18040997\n",
      "epoch = 9100    epoch_cost = 0.18011886\n",
      "epoch = 9200    epoch_cost = 0.17984042\n",
      "epoch = 9300    epoch_cost = 0.17956264\n",
      "epoch = 9400    epoch_cost = 0.17928661\n",
      "epoch = 9500    epoch_cost = 0.1790277\n",
      "epoch = 9600    epoch_cost = 0.17878227\n",
      "epoch = 9700    epoch_cost = 0.17854646\n",
      "epoch = 9800    epoch_cost = 0.1783211\n",
      "epoch = 9900    epoch_cost = 0.17810598\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数已经保存到session。\n",
      "训练集的准确率： 1.0\n",
      "测试集的准确率: 1.0\n"
     ]
    }
   ],
   "source": [
    "parameters=model(X_train,y_train,X_test,y_test,\n",
    "        learning_rate=0.0001,num_epochs=10000,print_cost=True,is_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "\n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "\n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "             }\n",
    "\n",
    "    x=tf.placeholder(tf.float32,[5,None],name=\"x\")\n",
    "\n",
    "    z2 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z2)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\",\n",
    "                  the shapes are given in initialize_parameters\n",
    "    Returns:\n",
    "    Z2 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "  \n",
    "    return Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.DataFrame()\n",
    "for i in range(10):\n",
    "    f1=pd.read_csv('/home/yazi/Documents/stage/data/car_afc_train/train'+str(i)+'_first.csv',delimiter=';',encoding='iso 8859-1',dtype=str)\n",
    "    f2=pd.read_csv('/home/yazi/Documents/stage/data/car_afc_train/train'+str(i)+'_last.csv',delimiter=';',encoding='iso 8859-1',dtype=str)\n",
    "    file=pd.concat([f1,f2,file],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(file.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.transpose(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.9182201 , -0.02140536,  0.3290835 , -0.3495785 , -1.3251526 ],\n",
       "        [ 0.26846367,  0.53528225,  0.30599096,  1.4606563 , -0.21910578],\n",
       "        [ 0.19581075,  0.18838267,  0.18309715, -0.277957  ,  0.22986947],\n",
       "        [ 0.97846293,  0.46235004, -0.2903828 , -1.1189848 , -0.49991965]],\n",
       "       dtype=float32), 'b1': array([[ 0.6663864 ],\n",
       "        [ 0.82757074],\n",
       "        [-0.3098831 ],\n",
       "        [ 0.5799382 ]], dtype=float32), 'W2': array([[-1.3922069 , -0.55741006,  0.52860534, -0.68395984]],\n",
       "       dtype=float32), 'b2': array([[-0.53168]], dtype=float32)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=predict(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from My_count import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 345710}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
